{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)\n",
    "\n",
    "The PCA is conduct by obtaining new parameters $z$ by mapping them with the old paramters $x$ in a linear relation.\n",
    "\n",
    "The correlation of $z$ and $x$ is linked by a loading weight $w$, saying how much weighting of each old parameters is considred by the new parameter $z$.\n",
    "\n",
    "$$\n",
    "z_1 = w_1^Tx\n",
    "$$\n",
    "\n",
    "To find the new $z$, we try to maximize the variance of the new $z$, such that it can capture the most information from the old $x$ into the new $z$, hence reducing the dimension of the paramter space.\n",
    "\n",
    "$$\n",
    "Var(z_1) = Var(w_1^Tx)\n",
    "$$\n",
    "$$\n",
    "= \n",
    "$$\n",
    "\n",
    "Since we try the maximize the loading weight, it has to be set on a constraint to prevent the weights bloating into excessive value. We try to limit the weights by noramlizing its distance into 1:\n",
    "$$\n",
    "||w_1|| = \\sum_{n}{w_{n1}^2} = 1\n",
    "$$\n",
    "\n",
    "This singly constrainted linear programming can be solved by differentiating the Lagrangian equation of the model with respect to the $w_1$\n",
    "$$\n",
    "\\mathcal{L}(w_1) = Var(z_1) - \\alpha (||w_1|| - 1)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}(w_1)}{\\partial{w_1}} = \n",
    "$$\n",
    "\n",
    "assuming this is a convex function (which is true when take 2nd derivitive to the equation)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
